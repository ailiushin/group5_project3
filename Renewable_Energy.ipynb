{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy potential: Bhumi (read pdf and figure out terms) & Ryan Cheng (Cleaning the data) US_Renewable_Energy_Technical_Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the file and creating a df\n",
    "potential_energy_path = 'Resources/Raw Data/US_Renewable_Energy_Technical_Potential.csv'\n",
    "potential_df = pd.read_csv(potential_energy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>urbanUtilityScalePV_GWh</th>\n",
       "      <th>ruralUtilityScalePV_GWh</th>\n",
       "      <th>rooftopPV_GWh</th>\n",
       "      <th>CSP_GWh</th>\n",
       "      <th>onshoreWind_GWh</th>\n",
       "      <th>offshoreWind_GWh</th>\n",
       "      <th>biopowerSolid_GWh</th>\n",
       "      <th>biopowerGaseous_GWh</th>\n",
       "      <th>geothermalHydrothermal_GWh</th>\n",
       "      <th>EGSGeothermal_GWh</th>\n",
       "      <th>hydropower_GWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>35850</td>\n",
       "      <td>3706838</td>\n",
       "      <td>15475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11193</td>\n",
       "      <td>1533</td>\n",
       "      <td>0</td>\n",
       "      <td>535489.0</td>\n",
       "      <td>4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>166</td>\n",
       "      <td>8282976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1373433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513</td>\n",
       "      <td>61</td>\n",
       "      <td>15437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>121305</td>\n",
       "      <td>11867693</td>\n",
       "      <td>22736.0</td>\n",
       "      <td>12544333</td>\n",
       "      <td>26036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1087</td>\n",
       "      <td>837</td>\n",
       "      <td>8329</td>\n",
       "      <td>1239147.0</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>28960</td>\n",
       "      <td>4986388</td>\n",
       "      <td>8484.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14381</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>628621.0</td>\n",
       "      <td>6093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>246008</td>\n",
       "      <td>8855917</td>\n",
       "      <td>106411.0</td>\n",
       "      <td>8490916</td>\n",
       "      <td>89862</td>\n",
       "      <td>2662579.0</td>\n",
       "      <td>12408</td>\n",
       "      <td>15510</td>\n",
       "      <td>130921</td>\n",
       "      <td>1344179.0</td>\n",
       "      <td>30023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       States  urbanUtilityScalePV_GWh  ruralUtilityScalePV_GWh  \\\n",
       "0     Alabama                    35850                  3706838   \n",
       "1      Alaska                      166                  8282976   \n",
       "2     Arizona                   121305                 11867693   \n",
       "3    Arkansas                    28960                  4986388   \n",
       "4  California                   246008                  8855917   \n",
       "\n",
       "   rooftopPV_GWh   CSP_GWh  onshoreWind_GWh  offshoreWind_GWh  \\\n",
       "0        15475.0         0              283               0.0   \n",
       "1            NaN         0          1373433               NaN   \n",
       "2        22736.0  12544333            26036               NaN   \n",
       "3         8484.0         0            22892               NaN   \n",
       "4       106411.0   8490916            89862         2662579.0   \n",
       "\n",
       "   biopowerSolid_GWh  biopowerGaseous_GWh  geothermalHydrothermal_GWh  \\\n",
       "0              11193                 1533                           0   \n",
       "1                513                   61                       15437   \n",
       "2               1087                  837                        8329   \n",
       "3              14381                 1063                           0   \n",
       "4              12408                15510                      130921   \n",
       "\n",
       "   EGSGeothermal_GWh  hydropower_GWh  \n",
       "0           535489.0            4102  \n",
       "1                NaN           23675  \n",
       "2          1239147.0            1303  \n",
       "3           628621.0            6093  \n",
       "4          1344179.0           30023  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the unnessecary columns of the df\n",
    "potential_df = potential_df.drop({'urbanUtilityScalePV_GW', 'urbanUtilityScalePV_km2', \n",
    "                                'ruralUtilityScalePV_GW', 'ruralUtilityScalePV_km2', 'rooftopPV_GW', \n",
    "                                'CSP_GW', 'CSP_km2', 'onshoreWind_GW', 'onshoreWind_km2', 'offshoreWind_GW', \n",
    "                                'offshoreWind_km2', 'biopowerSolid_GW', 'biopowerSolid_BDT', \n",
    "                                'biopowerGaseous_GW', 'biopowerGaseous_Tonnes-CH4', \n",
    "                                'geothermalHydrothermal_GW', 'EGSGeothermal_GW', 'hydropower_GW', \n",
    "                                'hydropower_countOfSites'}, axis = 1)\n",
    "# naming the 1st column as it was not named before\n",
    "potential_df.rename(columns = {'Unnamed: 0':'States'}, inplace=True)\n",
    "potential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>urbanUtilityScalePV_GWh</th>\n",
       "      <th>ruralUtilityScalePV_GWh</th>\n",
       "      <th>rooftopPV_GWh</th>\n",
       "      <th>CSP_GWh</th>\n",
       "      <th>onshoreWind_GWh</th>\n",
       "      <th>offshoreWind_GWh</th>\n",
       "      <th>biopowerSolid_GWh</th>\n",
       "      <th>biopowerGaseous_GWh</th>\n",
       "      <th>geothermalHydrothermal_GWh</th>\n",
       "      <th>EGSGeothermal_GWh</th>\n",
       "      <th>hydropower_GWh</th>\n",
       "      <th>Solar Energy Total Potential</th>\n",
       "      <th>Wind Energy Total Potential</th>\n",
       "      <th>Bio Energy Total Potential</th>\n",
       "      <th>Geothermal Energy Total Potential</th>\n",
       "      <th>Hydropower Energy Total Potential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>35850</td>\n",
       "      <td>3706838</td>\n",
       "      <td>15475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11193</td>\n",
       "      <td>1533</td>\n",
       "      <td>0</td>\n",
       "      <td>535489.0</td>\n",
       "      <td>4102</td>\n",
       "      <td>3758163.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>12726</td>\n",
       "      <td>535489.0</td>\n",
       "      <td>4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>166</td>\n",
       "      <td>8282976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1373433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513</td>\n",
       "      <td>61</td>\n",
       "      <td>15437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23675</td>\n",
       "      <td>8283142.0</td>\n",
       "      <td>1373433.0</td>\n",
       "      <td>574</td>\n",
       "      <td>15437.0</td>\n",
       "      <td>23675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>121305</td>\n",
       "      <td>11867693</td>\n",
       "      <td>22736.0</td>\n",
       "      <td>12544333</td>\n",
       "      <td>26036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1087</td>\n",
       "      <td>837</td>\n",
       "      <td>8329</td>\n",
       "      <td>1239147.0</td>\n",
       "      <td>1303</td>\n",
       "      <td>24556067.0</td>\n",
       "      <td>26036.0</td>\n",
       "      <td>1924</td>\n",
       "      <td>1247476.0</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>28960</td>\n",
       "      <td>4986388</td>\n",
       "      <td>8484.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14381</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>628621.0</td>\n",
       "      <td>6093</td>\n",
       "      <td>5023832.0</td>\n",
       "      <td>22892.0</td>\n",
       "      <td>15444</td>\n",
       "      <td>628621.0</td>\n",
       "      <td>6093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>246008</td>\n",
       "      <td>8855917</td>\n",
       "      <td>106411.0</td>\n",
       "      <td>8490916</td>\n",
       "      <td>89862</td>\n",
       "      <td>2662579.0</td>\n",
       "      <td>12408</td>\n",
       "      <td>15510</td>\n",
       "      <td>130921</td>\n",
       "      <td>1344179.0</td>\n",
       "      <td>30023</td>\n",
       "      <td>17699252.0</td>\n",
       "      <td>2752441.0</td>\n",
       "      <td>27918</td>\n",
       "      <td>1475100.0</td>\n",
       "      <td>30023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       States  urbanUtilityScalePV_GWh  ruralUtilityScalePV_GWh  \\\n",
       "0     Alabama                    35850                  3706838   \n",
       "1      Alaska                      166                  8282976   \n",
       "2     Arizona                   121305                 11867693   \n",
       "3    Arkansas                    28960                  4986388   \n",
       "4  California                   246008                  8855917   \n",
       "\n",
       "   rooftopPV_GWh   CSP_GWh  onshoreWind_GWh  offshoreWind_GWh  \\\n",
       "0        15475.0         0              283               0.0   \n",
       "1            NaN         0          1373433               NaN   \n",
       "2        22736.0  12544333            26036               NaN   \n",
       "3         8484.0         0            22892               NaN   \n",
       "4       106411.0   8490916            89862         2662579.0   \n",
       "\n",
       "   biopowerSolid_GWh  biopowerGaseous_GWh  geothermalHydrothermal_GWh  \\\n",
       "0              11193                 1533                           0   \n",
       "1                513                   61                       15437   \n",
       "2               1087                  837                        8329   \n",
       "3              14381                 1063                           0   \n",
       "4              12408                15510                      130921   \n",
       "\n",
       "   EGSGeothermal_GWh  hydropower_GWh  Solar Energy Total Potential  \\\n",
       "0           535489.0            4102                     3758163.0   \n",
       "1                NaN           23675                     8283142.0   \n",
       "2          1239147.0            1303                    24556067.0   \n",
       "3           628621.0            6093                     5023832.0   \n",
       "4          1344179.0           30023                    17699252.0   \n",
       "\n",
       "   Wind Energy Total Potential  Bio Energy Total Potential  \\\n",
       "0                        283.0                       12726   \n",
       "1                    1373433.0                         574   \n",
       "2                      26036.0                        1924   \n",
       "3                      22892.0                       15444   \n",
       "4                    2752441.0                       27918   \n",
       "\n",
       "   Geothermal Energy Total Potential  Hydropower Energy Total Potential  \n",
       "0                           535489.0                               4102  \n",
       "1                            15437.0                              23675  \n",
       "2                          1247476.0                               1303  \n",
       "3                           628621.0                               6093  \n",
       "4                          1475100.0                              30023  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating new columns for each type of energy (solar, wind, bio, geothermal, hydro) by summing the\n",
    "# respective data\n",
    "solar_list = ['urbanUtilityScalePV_GWh', 'ruralUtilityScalePV_GWh', 'rooftopPV_GWh', \n",
    "                                    'CSP_GWh']\n",
    "potential_df['Solar Energy Total Potential (GWh)'] = potential_df[solar_list].sum(axis=1)\n",
    "\n",
    "wind_list = ['onshoreWind_GWh', 'offshoreWind_GWh']\n",
    "potential_df['Wind Energy Total Potential (GWh)'] = potential_df[wind_list].sum(axis=1)\n",
    "\n",
    "bio_list = ['biopowerSolid_GWh', 'biopowerGaseous_GWh']\n",
    "potential_df['Bio Energy Total Potential (GWh)'] = potential_df[bio_list].sum(axis=1)\n",
    "\n",
    "geo_list = ['geothermalHydrothermal_GWh', 'EGSGeothermal_GWh']\n",
    "potential_df['Geothermal Energy Total Potential (GWh)'] = potential_df[geo_list].sum(axis=1)\n",
    "\n",
    "potential_df['Hydropower Energy Total Potential (GWh)'] = potential_df['hydropower_GWh']\n",
    "potential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old  code for reference only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_data/Chicago_Crimes_2019.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\FINEST~1\\AppData\\Local\\Temp/ipykernel_27980/3674278165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# importing csv files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcrimes_19\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input_data/Chicago_Crimes_2019.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcrimes_20\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input_data/Chicago_Crimes_2020.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcrimes_21\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input_data/Chicago_Crimes_2021.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfbi_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input_data/FBI_Code.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ISO-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_data/Chicago_Crimes_2019.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# importing csv files.\n",
    "crimes_19 = pd.read_csv('input_data/Chicago_Crimes_2019.csv')\n",
    "crimes_20 = pd.read_csv('input_data/Chicago_Crimes_2020.csv')\n",
    "crimes_21 = pd.read_csv('input_data/Chicago_Crimes_2021.csv')\n",
    "fbi_code = pd.read_csv('input_data/FBI_Code.csv', encoding = \"ISO-8859-1\")\n",
    "#fbi_code = pd.read_csv('input_data/FBI_Code.csv',  encoding= 'unicode_escape')\n",
    "iucr_code = pd.read_csv('input_data/IUCR_Codes.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# merging crimes data for the last 3 years into a signle dataframe\n",
    "crimes_data = pd.merge((pd.merge(crimes_19,crimes_20, how=\"outer\")),crimes_21,how=\"outer\")\n",
    "\n",
    "print(len(crimes_data))\n",
    "\n",
    "#Loading the FBI cvs file\n",
    "df = fbi_code\n",
    "df.head()\n",
    "\n",
    "#Loading the IUCS cvs file\n",
    "df2 = iucr_code\n",
    "df2.head(10)\n",
    "\n",
    "#dropping unnecessary columns\n",
    "df = df.drop(df.columns[[2,3]], axis=1)\n",
    "df.columns=['code', 'description']\n",
    "df.head()\n",
    "\n",
    "#dropping unnecessary columns\n",
    "df2 = df2.drop(df2.columns[[3,4]], axis=1)\n",
    "df2.head()\n",
    "\n",
    "#Checking and Removing duplicates rows\n",
    "df = df.drop_duplicates()\n",
    "df.head()\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#df.to_csv(r'./Output_data/FBI_code.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#Checking and Removing duplicates rows\n",
    "df2 = df2.drop_duplicates()\n",
    "df2.head()\n",
    "\n",
    "#Rename Columns\n",
    "df2 = df2.rename(columns=({'PRIMARY DESCRIPTION':'PRIMARY_DESCRIPTION','SECONDARY DESCRIPTION':'SECONDARY_DESCRIPTION'}))\n",
    "df2.head()\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#df2.to_csv(r'./Output_data/ICUS_code.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# merging crimes data for the last 3 years into a signle dataframe\n",
    "crimes_data = pd.merge((pd.merge(crimes_19,crimes_20, how=\"outer\")),crimes_21,how=\"outer\")\n",
    "\n",
    "#dropping unnecessary columns\n",
    "crimes_data = crimes_data.drop(columns=['Latitude','Location','Longitude','X Coordinate','Y Coordinate','Updated On'])\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# removing duplicate values\n",
    "crimes_data = crimes_data.drop_duplicates()\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# removing missing values\n",
    "crimes_data = crimes_data.dropna()\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# Creating a function which will remove extra leading and tailing whitespace from the data.\n",
    "def whitespace_remover(crimes_data):\n",
    "   \n",
    "    # iterating over the columns\n",
    "    for i in crimes_data.columns:\n",
    "         \n",
    "        # checking datatype of each columns\n",
    "        if crimes_data[i].dtype == 'object':\n",
    "             \n",
    "            # applying strip function on column\n",
    "            crimes_data[i] = crimes_data[i].map(str.strip)\n",
    "        else:\n",
    "             \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "        \n",
    "# applyting whitespace_remover function on dataframe        \n",
    "whitespace_remover(crimes_data)\n",
    "\n",
    "#Rename Columns\n",
    "crimes_data = crimes_data.rename(columns=({'Case Number':'Case_Number',\n",
    "                                           'Location Description':'Location_Description',\n",
    "                                           'Community Area':'Community_Area',\n",
    "                                          'FBI Code':'FBI_Code'}))\n",
    "\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#crimes_data.to_csv(r'./Output_data/crimes_data.csv', encoding='utf-8', index=False)\n",
    "crimes_data.head(20)\n",
    "\n",
    "# create database connection\n",
    "connection_string = \"postgres:postgressql@localhost:5432/new_crime_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')\n",
    "# Confirm tables\n",
    "engine.table_names()\n",
    "\n",
    "# rename columns to lower case \n",
    "df2.rename(columns={'IUCR':'iucr','PRIMARY_DESCRIPTION':'primary_description','SECONDARY_DESCRIPTION':'secondary_description' }, inplace=True)\n",
    "crimes_data.columns=['id', 'case_number', 'date', 'block', 'iucr','location_description',\n",
    "                     'arrest', 'domestic','beat','district', 'district_name', 'district_population',\n",
    "                     'ward', 'community_area', 'fbi_code'\n",
    "                    ]\n",
    "\n",
    "#load dataframe into database for the FBI and IUCR codes\n",
    "\n",
    "df2.to_sql(name='iucr_codes', con=engine, if_exists='append', index=False)\n",
    "df.to_sql(name='fbi_description', con=engine, if_exists='append', index=False)\n",
    "\n",
    "#load dataframe into database for the crimes data\n",
    "crimes_data.to_sql(name='crime_table', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy_consumption: Rafael (TBD) & Ryan Callaghan (TBD) US_Total_Energy_Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artem - Webscraping & lats/Longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proving url address\n",
    "url  = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population#cite_note-5\"\n",
    "\n",
    "# sleep for 1 second before reading url\n",
    "time.sleep(1)\n",
    "\n",
    "# scrape wiki url\n",
    "wiki_data = pd.read_html(url)\n",
    "# type(wiki_data)\n",
    "\n",
    "# select the first table from the list of tables and convert to DataFrame\n",
    "population_table = pd.DataFrame(wiki_data[0])\n",
    "population_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD (most likely Ryan + someone else) - Postgress -> push to DB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
