{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy potential: Bhumi (read pdf and figure out terms) & Ryan Cheng (Cleaning the data) US_Renewable_Energy_Technical_Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old  code for reference only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing csv files.\n",
    "crimes_19 = pd.read_csv('input_data/Chicago_Crimes_2019.csv')\n",
    "crimes_20 = pd.read_csv('input_data/Chicago_Crimes_2020.csv')\n",
    "crimes_21 = pd.read_csv('input_data/Chicago_Crimes_2021.csv')\n",
    "fbi_code = pd.read_csv('input_data/FBI_Code.csv', encoding = \"ISO-8859-1\")\n",
    "#fbi_code = pd.read_csv('input_data/FBI_Code.csv',  encoding= 'unicode_escape')\n",
    "iucr_code = pd.read_csv('input_data/IUCR_Codes.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# merging crimes data for the last 3 years into a signle dataframe\n",
    "crimes_data = pd.merge((pd.merge(crimes_19,crimes_20, how=\"outer\")),crimes_21,how=\"outer\")\n",
    "\n",
    "print(len(crimes_data))\n",
    "\n",
    "#Loading the FBI cvs file\n",
    "df = fbi_code\n",
    "df.head()\n",
    "\n",
    "#Loading the IUCS cvs file\n",
    "df2 = iucr_code\n",
    "df2.head(10)\n",
    "\n",
    "#dropping unnecessary columns\n",
    "df = df.drop(df.columns[[2,3]], axis=1)\n",
    "df.columns=['code', 'description']\n",
    "df.head()\n",
    "\n",
    "#dropping unnecessary columns\n",
    "df2 = df2.drop(df2.columns[[3,4]], axis=1)\n",
    "df2.head()\n",
    "\n",
    "#Checking and Removing duplicates rows\n",
    "df = df.drop_duplicates()\n",
    "df.head()\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#df.to_csv(r'./Output_data/FBI_code.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#Checking and Removing duplicates rows\n",
    "df2 = df2.drop_duplicates()\n",
    "df2.head()\n",
    "\n",
    "#Rename Columns\n",
    "df2 = df2.rename(columns=({'PRIMARY DESCRIPTION':'PRIMARY_DESCRIPTION','SECONDARY DESCRIPTION':'SECONDARY_DESCRIPTION'}))\n",
    "df2.head()\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#df2.to_csv(r'./Output_data/ICUS_code.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# merging crimes data for the last 3 years into a signle dataframe\n",
    "crimes_data = pd.merge((pd.merge(crimes_19,crimes_20, how=\"outer\")),crimes_21,how=\"outer\")\n",
    "\n",
    "#dropping unnecessary columns\n",
    "crimes_data = crimes_data.drop(columns=['Latitude','Location','Longitude','X Coordinate','Y Coordinate','Updated On'])\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# removing duplicate values\n",
    "crimes_data = crimes_data.drop_duplicates()\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# removing missing values\n",
    "crimes_data = crimes_data.dropna()\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# Creating a function which will remove extra leading and tailing whitespace from the data.\n",
    "def whitespace_remover(crimes_data):\n",
    "   \n",
    "    # iterating over the columns\n",
    "    for i in crimes_data.columns:\n",
    "         \n",
    "        # checking datatype of each columns\n",
    "        if crimes_data[i].dtype == 'object':\n",
    "             \n",
    "            # applying strip function on column\n",
    "            crimes_data[i] = crimes_data[i].map(str.strip)\n",
    "        else:\n",
    "             \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "        \n",
    "# applyting whitespace_remover function on dataframe        \n",
    "whitespace_remover(crimes_data)\n",
    "\n",
    "#Rename Columns\n",
    "crimes_data = crimes_data.rename(columns=({'Case Number':'Case_Number',\n",
    "                                           'Location Description':'Location_Description',\n",
    "                                           'Community Area':'Community_Area',\n",
    "                                          'FBI Code':'FBI_Code'}))\n",
    "\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#crimes_data.to_csv(r'./Output_data/crimes_data.csv', encoding='utf-8', index=False)\n",
    "crimes_data.head(20)\n",
    "\n",
    "# create database connection\n",
    "connection_string = \"postgres:postgressql@localhost:5432/new_crime_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')\n",
    "# Confirm tables\n",
    "engine.table_names()\n",
    "\n",
    "# rename columns to lower case \n",
    "df2.rename(columns={'IUCR':'iucr','PRIMARY_DESCRIPTION':'primary_description','SECONDARY_DESCRIPTION':'secondary_description' }, inplace=True)\n",
    "crimes_data.columns=['id', 'case_number', 'date', 'block', 'iucr','location_description',\n",
    "                     'arrest', 'domestic','beat','district', 'district_name', 'district_population',\n",
    "                     'ward', 'community_area', 'fbi_code'\n",
    "                    ]\n",
    "\n",
    "#load dataframe into database for the FBI and IUCR codes\n",
    "\n",
    "df2.to_sql(name='iucr_codes', con=engine, if_exists='append', index=False)\n",
    "df.to_sql(name='fbi_description', con=engine, if_exists='append', index=False)\n",
    "\n",
    "#load dataframe into database for the crimes data\n",
    "crimes_data.to_sql(name='crime_table', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy_consumption: Rafael (TBD) & Ryan Callaghan (TBD) US_Total_Energy_Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artem - Webscraping & lats/Longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>39237836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>29527941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>21781128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>19835913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>12964056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          State  Population\n",
       "0    California    39237836\n",
       "1         Texas    29527941\n",
       "2       Florida    21781128\n",
       "3      New York    19835913\n",
       "4  Pennsylvania    12964056"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proving url address\n",
    "url  = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population#cite_note-5\"\n",
    "\n",
    "# sleep for 1 second before reading url\n",
    "time.sleep(1)\n",
    "\n",
    "# scrape wiki url\n",
    "wiki_data = pd.read_html(url)\n",
    "# type(wiki_data)\n",
    "\n",
    "# select the first table from the list of tables and convert to DataFrame\n",
    "population_table = pd.DataFrame(wiki_data[0])\n",
    "\n",
    "# dropping first level of multi index column headers\n",
    "population_2021 = population_table.droplevel(0, axis=1) \n",
    "\n",
    "# selecting state and population as of 2021 columns\n",
    "population_2021 = population_2021 [['State or territory','July 1, 2021']]\n",
    "\n",
    "# rename columns \n",
    "population_2021 = population_2021.rename(columns=({'State or territory':'State','July 1, 2021':'Population'}))\n",
    "\n",
    "# removing extra rows\n",
    "population_2021 = population_2021[0:52]\n",
    "\n",
    "# remving territories\n",
    "population_2021 = population_2021.drop(labels=[29,49], axis=0)\n",
    "population_2021.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD (most likely Ryan + someone else) - Postgress -> push to DB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData38]",
   "language": "python",
   "name": "conda-env-PythonData38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
